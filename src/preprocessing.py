import numpy as np
import pandas as pd

from pathlib import Path

# Absolute path (relative to the parent directory of the script's location)
SCRIPT_DIR = Path(__file__).parent
DATA_DIR = SCRIPT_DIR.parent / "data"
INPUT_HISTORY_CSV = '01_input_history.csv'
PROCESSED_DATA_CSV = DATA_DIR / 'processed_data.csv'

# Ensure the input file exists
if not (DATA_DIR / INPUT_HISTORY_CSV).exists():
    raise FileNotFoundError(f"Input file {(DATA_DIR / INPUT_HISTORY_CSV)} not found.")

class Preprocess:

    def __init__(self, data):
        self.df = data.copy()
        self.feature_cols = None  # To store final feature column names
        self.categorical_features = ['Country', 'Product']  # Keep track

    def get_data(self):
        return self.df

    def get_feature_columns(self):
        if self.feature_cols is None:
            raise ValueError("Preprocessing (feature generation) must be run first.")
        exclude_cols = ['Quantity', 'Year', 'Month_Num', 'Month', 'ds']
        return [col for col in self.feature_cols if col not in exclude_cols]

    def parse_dates(self, prophet_format=False):
        """Parses the Month column into Year and Month numbers, adds cyclical features."""
        month_map = {
            "Jan": 1, "Feb": 2, "Mar": 3, "Apr": 4, "May": 5, "Jun": 6,
            "Jul": 7, "Aug": 8, "Sep": 9, "Oct": 10, "Nov": 11, "Dec": 12
        }
        month_abbrev_map = {v: k for k, v in month_map.items()}

        def parse_month_year(mmyyyy):
            month_abbrev = mmyyyy[:3]
            year_str = mmyyyy[3:]
            if not year_str.isdigit():
                raise ValueError(f"Could not parse year from '{mmyyyy}'")
            year = int(year_str)
            if month_abbrev not in month_map:
                raise ValueError(f"Could not parse month abbreviation from '{mmyyyy}'")
            month = month_map[month_abbrev]
            return year, month

        if 'Year' in self.df.columns and 'Month_Num' in self.df.columns:
            print("Date columns 'Year' and 'Month_Num' already exist. Skipping parsing.")
            self.df['Year'] = self.df['Year'].astype(int)
            self.df['Month_Num'] = self.df['Month_Num'].astype(int)
        elif 'Month' in self.df.columns and isinstance(self.df['Month'].iloc[0], str):
            print("Parsing 'Month' column...")
            parsed_dates = self.df['Month'].apply(
                lambda x: pd.Series(parse_month_year(x), index=['Year', 'Month_Num'])
            )
            self.df = pd.concat([self.df, parsed_dates], axis=1)
        else:
            raise ValueError("Cannot parse dates. Requires either 'Month' (string) or 'Year'/'Month_Num' columns.")

        self.df['month_sin'] = np.sin(2 * np.pi * self.df['Month_Num'] / 12)
        self.df['month_cos'] = np.cos(2 * np.pi * self.df['Month_Num'] / 12)

        if prophet_format:
            self.df['ds'] = pd.to_datetime(
                self.df['Year'].astype(str) + '-' +
                self.df['Month_Num'].astype(str).str.zfill(2) + '-01'
            )
            self.df['y'] = self.df['Quantity']

    def generate_features(self, rolling_window=6, lag_periods=[1, 2, 3, 12]):
        """Creates lagged and rolling features."""
        if not all(col in self.df.columns for col in ['Country', 'Product', 'Year', 'Month_Num', 'Quantity']):
            raise ValueError("Required columns ('Country', 'Product', 'Year', 'Month_Num', 'Quantity') not found. Run parse_dates first.")

        self.df.sort_values(by=['Country', 'Product', 'Year', 'Month_Num'], inplace=True)
        self.df.reset_index(drop=True, inplace=True)
        group_cols = ['Country', 'Product']

        print(f"Generating lags: {lag_periods}")
        for lag in lag_periods:
            self.df[f'lag_{lag}'] = self.df.groupby(group_cols)['Quantity'].shift(lag)

        print(f"Generating rolling mean with window: {rolling_window}")
        self.df[f'rolling_mean_{rolling_window}'] = self.df.groupby(group_cols)['Quantity'].transform(
            lambda x: x.shift(1).rolling(window=rolling_window, min_periods=1).mean()
        )
        print(f"Generating rolling std dev with window: {rolling_window}")
        self.df[f'rolling_std_{rolling_window}'] = self.df.groupby(group_cols)['Quantity'].transform(
            lambda x: x.shift(1).rolling(window=rolling_window, min_periods=1).std()
        )

        print("Filling NaNs generated by lags/rolling features...")
        feature_cols_to_fill = [
            f'lag_{lag}' for lag in lag_periods
        ] + [f'rolling_mean_{rolling_window}', f'rolling_std_{rolling_window}']
        self.df.fillna({col: 0 for col in feature_cols_to_fill}, inplace=True)

        print("Feature generation complete.")

    def handle_categorical(self):
        """Converts categorical features to a format suitable for LightGBM."""
        print("Converting categorical features...")
        for col in self.categorical_features:
            if col in self.df.columns:
                self.df[col] = self.df[col].astype('category')
            else:
                print(f"Warning: Categorical column '{col}' not found in DataFrame.")

    def full_preprocess(self, rolling_window=6, lag_periods=[1, 2, 3, 12]):
        """Consolidated preprocessing steps."""
        print("--- Starting Full Preprocessing ---")
        self.parse_dates()
        self.generate_features(rolling_window=rolling_window, lag_periods=lag_periods)
        self.handle_categorical()

        potential_features = list(self.df.columns)
        exclude_cols = ['Quantity', 'Month', 'ds', 'y']
        self.feature_cols = [col for col in potential_features if col not in exclude_cols]

        print("--- Preprocessing Complete ---")
        return self.df

    def save_processed_data(self, path=PROCESSED_DATA_CSV):
        """Save the processed DataFrame to a CSV file."""
        print(f"Saving processed data to {path}...")
        try:
            self.df.to_csv(path, index=False)
            print("Save successful.")
        except Exception as e:
            print(f"Error saving processed data: {e}")

    @staticmethod
    def get_train_val_split(data, val_year):
        """Splits data into training and validation sets based on year."""
        if 'Year' not in data.columns:
            raise ValueError("Column 'Year' needed for splitting.")

        train_data = data[data['Year'] < val_year].copy()
        val_data = data[data['Year'] == val_year].copy()

        print(f"Train data shape: {train_data.shape}")
        print(f"Validation data shape: {val_data.shape}")
        return train_data, val_data

    @staticmethod
    def get_data_for_final_train(data, forecast_start_year):
        """Gets all data before the forecast period for final training."""
        if 'Year' not in data.columns:
            raise ValueError("Column 'Year' needed for final training selection.")
        return data[data['Year'] < forecast_start_year].copy()



